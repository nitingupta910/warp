{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises: Meshes\n",
    "\n",
    "Build your understanding of the concepts from `core_04_meshes.ipynb`.\n",
    "\n",
    "This notebook covers:\n",
    "- **Triangular meshes** (`wp.Mesh`) and how Warp represents them\n",
    "- **2D kernel launches** using `wp.tid()` with two dimensions\n",
    "- **Signed Distance Fields (SDFs)** via `wp.mesh_query_point()`\n",
    "- **Color maps** to visualize scalar fields\n",
    "- **Raycasting** via `wp.mesh_query_ray()`\n",
    "\n",
    "Each exercise has an empty code cell — fill it in, run it, and check the assertions.\n",
    "If you get stuck, refer back to the tutorial notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import warp as wp\n",
    "\n",
    "wp.config.quiet = True\n",
    "wp.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise 1: What Is a Triangular Mesh?\n",
    "\n",
    "### Think first\n",
    "\n",
    "A triangular mesh is the most common way to represent 3D surfaces in computer graphics\n",
    "and simulation. It consists of:\n",
    "- **Points** (vertices): a list of 3D positions\n",
    "- **Indices** (faces): groups of 3 indices into the points array, each defining a triangle\n",
    "\n",
    "For example, a single triangle uses 3 points and 3 indices `[0, 1, 2]`.\n",
    "A square can be made from 4 points and 6 indices (two triangles sharing an edge).\n",
    "\n",
    "**Question:** If you have 4 points forming a square in the XZ plane, how many triangles\n",
    "do you need? How many index values is that?\n",
    "\n",
    "<details>\n",
    "<summary>Discussion</summary>\n",
    "\n",
    "You need **2 triangles** to tile a square. Each triangle needs 3 index values,\n",
    "so that's **6 index values** total. For example, with points at corners 0, 1, 2, 3,\n",
    "you might use triangles `[0, 1, 2]` and `[0, 2, 3]`.\n",
    "</details>\n",
    "\n",
    "### Now write it\n",
    "\n",
    "Create a `wp.Mesh` from a simple square (4 points, 2 triangles) lying in the XZ plane\n",
    "at `y=0`, spanning from `(-1, 0, -1)` to `(1, 0, 1)`.\n",
    "\n",
    "Warp meshes are created with:\n",
    "```python\n",
    "mesh = wp.Mesh(\n",
    "    points=wp.array(..., dtype=wp.vec3),\n",
    "    indices=wp.array(..., dtype=int),\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here.\n",
    "#\n",
    "# Define 4 points forming a square in the XZ plane (y=0).\n",
    "# Define 6 indices (2 triangles) covering the square.\n",
    "# Create a wp.Mesh and store it in a variable called `square_mesh`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Assertions (do not modify) ---\n",
    "assert square_mesh.points.shape == (4,), f\"Expected 4 points, got shape {square_mesh.points.shape}\"\n",
    "assert square_mesh.indices.shape == (6,), f\"Expected 6 indices, got shape {square_mesh.indices.shape}\"\n",
    "pts = square_mesh.points.numpy()\n",
    "assert np.all(pts[:, 1] == 0.0), \"All points should have y=0\"\n",
    "print(f\"Mesh created: {square_mesh.points.shape[0]} points, {square_mesh.indices.shape[0] // 3} triangles\")\n",
    "print(\"Passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise 2: 2D Kernel Launches\n",
    "\n",
    "### Think first\n",
    "\n",
    "So far you've launched kernels over 1D grids: `dim=N` gives you `i = wp.tid()`\n",
    "ranging from 0 to N-1.\n",
    "\n",
    "But for image/texture operations, a **2D grid** is natural. When you launch with\n",
    "`dim=(width, height)`, `wp.tid()` returns **two** values:\n",
    "```python\n",
    "j, i = wp.tid()  # j = column (0..width-1), i = row (0..height-1)\n",
    "```\n",
    "\n",
    "**Important:** The first value corresponds to the first dimension (width/columns),\n",
    "and the second to the second dimension (height/rows). When indexing a 2D array\n",
    "stored as `[rows, cols]`, you typically write `array[i, j]` (row first).\n",
    "\n",
    "**Question:** If you launch a kernel with `dim=(300, 200)`, how many threads run in total?\n",
    "What range does the first `wp.tid()` value cover?\n",
    "\n",
    "<details>\n",
    "<summary>Discussion</summary>\n",
    "\n",
    "Total threads = 300 * 200 = 60,000. The first value from `wp.tid()` ranges from\n",
    "0 to 299, and the second from 0 to 199.\n",
    "</details>\n",
    "\n",
    "### Now write it\n",
    "\n",
    "Write a kernel that fills a 2D array of `wp.vec3` with a color gradient.\n",
    "Each pixel should be `wp.vec3(j / width, i / height, 0.0)` — so the red channel\n",
    "increases left-to-right, and green increases top-to-bottom.\n",
    "\n",
    "Use a `(16, 8)` grid (16 columns, 8 rows)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here.\n",
    "#\n",
    "# Write a @wp.kernel called `fill_gradient` that takes:\n",
    "#   width: float\n",
    "#   height: float\n",
    "#   out: wp.array(dtype=wp.vec3, ndim=2)\n",
    "#\n",
    "# Use j, i = wp.tid() and set out[i, j] to the gradient color.\n",
    "# Then create a (8, 16) array (rows, cols) and launch with dim=(16, 8).\n",
    "# Store the result array in a variable called `gradient`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Assertions (do not modify) ---\n",
    "g = gradient.numpy()\n",
    "assert g.shape == (8, 16, 3), f\"Expected shape (8, 16, 3), got {g.shape}\"\n",
    "# Top-left corner should be (0, 0, 0)\n",
    "np.testing.assert_allclose(g[0, 0], [0.0, 0.0, 0.0], atol=0.01)\n",
    "# Bottom-right corner should be close to (1, 1, 0) — but not exactly 1.0\n",
    "# because we divide by width/height, giving (15/16, 7/8, 0)\n",
    "np.testing.assert_allclose(g[7, 15], [15.0 / 16.0, 7.0 / 8.0, 0.0], atol=0.01)\n",
    "print(\"Passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise 3: Mesh Point Queries\n",
    "\n",
    "### Think first\n",
    "\n",
    "`wp.mesh_query_point()` is the core building block for collision detection and SDFs.\n",
    "Given a mesh and a point in space, it finds the **closest location on the mesh surface**.\n",
    "\n",
    "It returns a query result with:\n",
    "- `result`: `bool` — whether a closest point was found\n",
    "- `sign`: `float` — positive if the point is **outside** the mesh, negative if **inside**\n",
    "- `face`: `int` — the triangle index containing the closest point\n",
    "- `u`, `v`: `float` — barycentric coordinates within that triangle\n",
    "\n",
    "You can then call `wp.mesh_eval_position(mesh_id, face, u, v)` to get the actual\n",
    "3D position of the closest point.\n",
    "\n",
    "**Question:** If you have a closed mesh (like a sphere) and a point inside it,\n",
    "what sign would `query.sign` have? What about a point outside?\n",
    "\n",
    "<details>\n",
    "<summary>Discussion</summary>\n",
    "\n",
    "A point **inside** the mesh gets `sign < 0` (negative), and a point **outside** gets\n",
    "`sign >= 0` (positive). This is the \"signed\" in \"Signed Distance Field\" — the sign\n",
    "tells you which side of the surface you're on.\n",
    "\n",
    "Note: sign detection only works reliably for **closed** (watertight) meshes. For open\n",
    "surfaces (like our flat square), the sign may not be meaningful.\n",
    "</details>\n",
    "\n",
    "### Now write it\n",
    "\n",
    "Write a kernel that takes an array of query points and a mesh, and computes the\n",
    "**unsigned distance** from each point to the closest surface location.\n",
    "\n",
    "Use the square mesh from Exercise 1 (or create a new one). Query from 3 points:\n",
    "1. `(0, 0, 0)` — on the surface (distance should be ~0)\n",
    "2. `(0, 1, 0)` — directly above center (distance should be ~1)\n",
    "3. `(0, 0.5, 0)` — halfway above center (distance should be ~0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here.\n",
    "#\n",
    "# Write a @wp.kernel called `compute_distance` that takes:\n",
    "#   mesh_id: wp.uint64\n",
    "#   query_points: wp.array(dtype=wp.vec3)\n",
    "#   distances: wp.array(dtype=float)\n",
    "#\n",
    "# For each point:\n",
    "#   1. Call wp.mesh_query_point(mesh_id, point, max_dist=1e6)\n",
    "#   2. Check query.result\n",
    "#   3. Use wp.mesh_eval_position(mesh_id, query.face, query.u, query.v)\n",
    "#      to get the nearest surface position\n",
    "#   4. Compute distance = wp.length(nearest_pos - point)\n",
    "#   5. Store in distances[i]\n",
    "#\n",
    "# Create the square mesh (or reuse from Exercise 1), set up the 3 query points,\n",
    "# and launch the kernel. Store distances in a variable called `dists`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Assertions (do not modify) ---\n",
    "d = dists.numpy()\n",
    "print(f\"Distances: {d}\")\n",
    "np.testing.assert_allclose(d[0], 0.0, atol=0.01, err_msg=\"Point on surface should have distance ~0\")\n",
    "np.testing.assert_allclose(d[1], 1.0, atol=0.01, err_msg=\"Point 1 unit above should have distance ~1\")\n",
    "np.testing.assert_allclose(d[2], 0.5, atol=0.01, err_msg=\"Point 0.5 units above should have distance ~0.5\")\n",
    "print(\"Passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise 4: Signed Distance Fields (SDFs)\n",
    "\n",
    "### Think first\n",
    "\n",
    "A **Signed Distance Field** assigns a signed distance value to every point in space:\n",
    "- **Negative** inside the mesh\n",
    "- **Zero** on the surface\n",
    "- **Positive** outside the mesh\n",
    "\n",
    "SDFs are widely used for:\n",
    "- **Collision detection**: check if `sdf < 0` to detect penetration\n",
    "- **Rendering**: ray march through the field to find surfaces\n",
    "- **Physics**: compute contact normals from the SDF gradient\n",
    "\n",
    "To compute an SDF value from a mesh query, you combine the distance with the sign:\n",
    "```python\n",
    "dist = wp.length(nearest_pos - point)\n",
    "sdf = dist if query.sign >= 0 else -dist\n",
    "```\n",
    "\n",
    "**Question:** For a sphere centered at the origin with radius 1, what SDF value\n",
    "would the point `(0, 0, 2)` have? What about `(0, 0, 0.5)`?\n",
    "\n",
    "<details>\n",
    "<summary>Discussion</summary>\n",
    "\n",
    "`(0, 0, 2)` is 1 unit outside the sphere surface, so SDF = +1.0.\n",
    "`(0, 0, 0.5)` is 0.5 units inside the sphere surface, so SDF = -0.5.\n",
    "The SDF of a sphere is simply `length(point) - radius`.\n",
    "</details>\n",
    "\n",
    "### Now write it\n",
    "\n",
    "Create a closed mesh (a tetrahedron — the simplest closed 3D shape) and compute\n",
    "the SDF at a few test points.\n",
    "\n",
    "A regular tetrahedron centered at the origin with vertices at:\n",
    "```\n",
    "(1, 1, 1), (1, -1, -1), (-1, 1, -1), (-1, -1, 1)\n",
    "```\n",
    "has 4 triangular faces (12 indices). The faces with outward-pointing normals are:\n",
    "```\n",
    "[0, 1, 2], [0, 2, 3], [0, 3, 1], [1, 3, 2]\n",
    "```\n",
    "\n",
    "Write a kernel that computes the **signed** distance. Test with:\n",
    "1. `(0, 0, 0)` — inside the tetrahedron (SDF should be negative)\n",
    "2. `(3, 3, 3)` — outside the tetrahedron (SDF should be positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here.\n",
    "#\n",
    "# 1. Create the tetrahedron mesh with the 4 vertices and 4 faces above.\n",
    "#    Store as `tet_mesh`.\n",
    "#\n",
    "# 2. Write a @wp.kernel called `compute_sdf` that takes:\n",
    "#      mesh_id: wp.uint64\n",
    "#      query_points: wp.array(dtype=wp.vec3)\n",
    "#      sdf_values: wp.array(dtype=float)\n",
    "#\n",
    "#    For each point, compute the signed distance using query.sign.\n",
    "#    If sign >= 0, sdf = +dist. If sign < 0, sdf = -dist.\n",
    "#\n",
    "# 3. Launch with the 2 test points and store SDF values in `sdf_vals`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Assertions (do not modify) ---\n",
    "s = sdf_vals.numpy()\n",
    "print(f\"SDF values: {s}\")\n",
    "assert s[0] < 0.0, f\"Origin should be inside (negative SDF), got {s[0]}\"\n",
    "assert s[1] > 0.0, f\"(3,3,3) should be outside (positive SDF), got {s[1]}\"\n",
    "print(\"Passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise 5: Color Maps\n",
    "\n",
    "### Think first\n",
    "\n",
    "A **color map** converts a scalar value (like an SDF distance) into an RGB color for\n",
    "visualization. The tutorial uses a \"Bourke color map\" — a piecewise-linear function\n",
    "that maps a range `[low, high]` through blue -> cyan -> green -> yellow -> red.\n",
    "\n",
    "The idea is simple: divide the range into 4 equal segments and linearly interpolate\n",
    "the R, G, B channels in each segment:\n",
    "\n",
    "| Range segment | Color transition |\n",
    "|---|---|\n",
    "| 0% - 25% | Blue (0,0,1) -> Cyan (0,1,1) |\n",
    "| 25% - 50% | Cyan (0,1,1) -> Green (0,1,0) |\n",
    "| 50% - 75% | Green (0,1,0) -> Yellow (1,1,0) |\n",
    "| 75% - 100% | Yellow (1,1,0) -> Red (1,0,0) |\n",
    "\n",
    "**Question:** What color would a value exactly at the midpoint of the range produce?\n",
    "\n",
    "<details>\n",
    "<summary>Discussion</summary>\n",
    "\n",
    "At the midpoint (50%), we're at the boundary between the cyan->green and green->yellow\n",
    "segments. At exactly 50%, red is just starting to increase from 0, green is 1, and blue\n",
    "is 0. So the color is green (0, 1, 0).\n",
    "</details>\n",
    "\n",
    "### Now write it\n",
    "\n",
    "Implement the Bourke color map as a `@wp.func`. The function should:\n",
    "1. Clamp `v` to `[low, high]`\n",
    "2. Compute `dv = high - low`\n",
    "3. Apply the 4-segment piecewise logic described above\n",
    "4. Return `wp.vec3(r, g, b)`\n",
    "\n",
    "Write a kernel that applies this to an array of float values and produces an array\n",
    "of `wp.vec3` colors. Test with values at the extremes and midpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here.\n",
    "#\n",
    "# 1. Write a @wp.func called `bourke_color_map` that takes:\n",
    "#      low: float, high: float, v: float -> wp.vec3\n",
    "#\n",
    "#    Start with r=1, g=1, b=1. Clamp v. Compute dv = high - low.\n",
    "#    Then apply the 4 conditions:\n",
    "#      if v < low + 0.25*dv:  r=0, g = 4*(v-low)/dv\n",
    "#      elif v < low + 0.5*dv: r=0, b = 1 + 4*(low+0.25*dv-v)/dv\n",
    "#      elif v < low + 0.75*dv: r = 4*(v-low-0.5*dv)/dv, b=0\n",
    "#      else: g = 1 + 4*(low+0.75*dv-v)/dv, b=0\n",
    "#\n",
    "# 2. Write a @wp.kernel called `apply_color_map` that takes:\n",
    "#      values: wp.array(dtype=float)\n",
    "#      low: float\n",
    "#      high: float\n",
    "#      colors: wp.array(dtype=wp.vec3)\n",
    "#\n",
    "# 3. Test with values [-1.0, -0.5, 0.0, 0.5, 1.0] mapped over range [-1, 1].\n",
    "#    Store the result in `colors`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Assertions (do not modify) ---\n",
    "c = colors.numpy()\n",
    "print(\"Colors:\")\n",
    "for i, v in enumerate([-1.0, -0.5, 0.0, 0.5, 1.0]):\n",
    "    print(f\"  v={v:+.1f} -> RGB=({c[i, 0]:.2f}, {c[i, 1]:.2f}, {c[i, 2]:.2f})\")\n",
    "# At low end (-1.0): should be blue-ish (r~0, g~0, b~1)\n",
    "assert c[0, 0] < 0.1, \"At low end, red should be ~0\"\n",
    "assert c[0, 2] > 0.9, \"At low end, blue should be ~1\"\n",
    "# At high end (1.0): should be red-ish (r~1, g~0, b~0)\n",
    "assert c[4, 0] > 0.9, \"At high end, red should be ~1\"\n",
    "assert c[4, 2] < 0.1, \"At high end, blue should be ~0\"\n",
    "# At midpoint (0.0): should be green-ish\n",
    "assert c[2, 1] > 0.9, \"At midpoint, green should be ~1\"\n",
    "print(\"Passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise 6: Rendering a 2D SDF Slice\n",
    "\n",
    "### Think first\n",
    "\n",
    "The tutorial renders a 2D \"slice\" of the mesh's SDF by:\n",
    "1. Setting up a 2D grid of pixels in the XZ plane (at `y=0`)\n",
    "2. For each pixel, computing its 3D position from its grid indices\n",
    "3. Querying the mesh to get the signed distance\n",
    "4. Mapping the SDF value to a color\n",
    "5. Storing the color in a 2D array and displaying with matplotlib\n",
    "\n",
    "The **pixel-to-world** mapping is:\n",
    "```python\n",
    "world_x = j * pixel_size + pixel_offset_x\n",
    "world_z = i * pixel_size + pixel_offset_z\n",
    "```\n",
    "\n",
    "The **pixel offset** centers the grid at the origin and places queries at pixel centers\n",
    "(not edges):\n",
    "```python\n",
    "pixel_offset = (pixel_size - grid_size) * 0.5\n",
    "```\n",
    "\n",
    "**Question:** Why do we add `pixel_size * 0.5` to the offset (embedded in the formula above)?\n",
    "What would happen without it?\n",
    "\n",
    "<details>\n",
    "<summary>Discussion</summary>\n",
    "\n",
    "Without the half-pixel offset, queries would be made from pixel corners instead of centers.\n",
    "This causes the rendered image to be shifted by half a pixel. For visualization it's a\n",
    "subtle difference, but for accurate SDF sampling it matters — you want each pixel's color\n",
    "to represent the SDF value at its center.\n",
    "\n",
    "The formula `(pixel_size - grid_size) * 0.5` combines two offsets:\n",
    "- `-grid_size * 0.5`: centers the grid at the origin\n",
    "- `+pixel_size * 0.5`: shifts to pixel centers\n",
    "</details>\n",
    "\n",
    "### Now write it\n",
    "\n",
    "Combine everything: create a tetrahedron mesh and render a 2D color-mapped SDF slice.\n",
    "\n",
    "This pulls together:\n",
    "- 2D kernel launch (Exercise 2)\n",
    "- Point queries and SDF (Exercises 3-4)\n",
    "- Bourke color map (Exercise 5)\n",
    "\n",
    "Use the tetrahedron from Exercise 4. Render a 200x200 pixel image of the XZ slice\n",
    "at `y=0`, covering a 4x4 region centered at the origin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here.\n",
    "#\n",
    "# 1. Define your bourke_color_map @wp.func (copy from Exercise 5 or redefine).\n",
    "#\n",
    "# 2. Write a @wp.kernel called `render_sdf_slice` that takes:\n",
    "#      pixel_size: float\n",
    "#      pixel_offset: wp.vec2\n",
    "#      mesh_id: wp.uint64\n",
    "#      sdf_band_width: float\n",
    "#      out_texture: wp.array(dtype=wp.vec3, ndim=2)\n",
    "#\n",
    "#    For each pixel (j, i = wp.tid()):\n",
    "#      a. Compute 3D position: x = j*pixel_size + offset[0], y = 0, z = i*pixel_size + offset[1]\n",
    "#      b. Query the mesh with wp.mesh_query_point()\n",
    "#      c. Compute signed distance\n",
    "#      d. Map to color with bourke_color_map using [-sdf_band_width/2, +sdf_band_width/2]\n",
    "#      e. Store in out_texture[i, j]\n",
    "#\n",
    "# 3. Set up the grid:\n",
    "#      grid_size = (4.0, 4.0)\n",
    "#      pixel_size = 0.02  (-> 200x200 resolution)\n",
    "#      sdf_band_width = 0.5 / pixel_size\n",
    "#\n",
    "# 4. Create the tetrahedron mesh, allocate the texture, launch the kernel.\n",
    "#    Store the texture array in `sdf_texture`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Assertions and visualization (do not modify) ---\n",
    "tex = sdf_texture.numpy()\n",
    "assert tex.shape[0] == 200 and tex.shape[1] == 200, f\"Expected 200x200, got {tex.shape[:2]}\"\n",
    "# Center pixel should be inside the mesh (blue-ish, since SDF is negative there)\n",
    "center = tex[100, 100]\n",
    "print(f\"Center pixel color: ({center[0]:.2f}, {center[1]:.2f}, {center[2]:.2f})\")\n",
    "# Corner pixel should be outside the mesh (red-ish, since SDF is positive)\n",
    "corner = tex[0, 0]\n",
    "print(f\"Corner pixel color: ({corner[0]:.2f}, {corner[1]:.2f}, {corner[2]:.2f})\")\n",
    "print(\"Passed!\")\n",
    "\n",
    "# Visualize (optional — requires matplotlib)\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "    ax.imshow(tex)\n",
    "    ax.set_title(\"SDF slice of tetrahedron (XZ plane)\")\n",
    "    ax.set_xlabel(\"X\")\n",
    "    ax.set_ylabel(\"Z\")\n",
    "    plt.show()\n",
    "except ImportError:\n",
    "    print(\"(matplotlib not available for visualization)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise 7: Ray-Mesh Intersection (Raycasting)\n",
    "\n",
    "### Think first\n",
    "\n",
    "**Raycasting** shoots rays from a viewpoint through each pixel of an image and checks\n",
    "what geometry the ray hits. It's the foundation of ray tracing renderers.\n",
    "\n",
    "`wp.mesh_query_ray()` finds where a ray intersects a mesh. It takes:\n",
    "- `mesh_id`: the mesh to test against\n",
    "- `ray_origin`: where the ray starts (`wp.vec3`)\n",
    "- `ray_dir`: the ray direction (`wp.vec3`, should be normalized)\n",
    "- `max_t`: maximum distance to check\n",
    "\n",
    "It returns a query result with:\n",
    "- `result`: `bool` — whether the ray hit anything\n",
    "- `normal`: `wp.vec3` — surface normal at the hit point\n",
    "- `t`: `float` — distance from origin to hit point along the ray\n",
    "- `face`, `u`, `v`: triangle and barycentric coordinates of the hit\n",
    "\n",
    "A common visualization trick: map the surface normal to a color by\n",
    "`color = normal * 0.5 + vec3(0.5)`. This shifts the `[-1, 1]` normal range to `[0, 1]`\n",
    "RGB range.\n",
    "\n",
    "**Question:** If a ray misses the mesh entirely, what color should the pixel be?\n",
    "\n",
    "<details>\n",
    "<summary>Discussion</summary>\n",
    "\n",
    "Black `(0, 0, 0)` — the background color. When `query.result` is `False`, we simply\n",
    "leave the pixel at its default/initialized value.\n",
    "</details>\n",
    "\n",
    "### Now write it\n",
    "\n",
    "Write a raycasting kernel that renders the tetrahedron by shooting rays from a camera\n",
    "and coloring pixels based on the surface normal at the hit point.\n",
    "\n",
    "Camera setup:\n",
    "- Origin at `(0, 0, 5)` (looking toward the origin)\n",
    "- For each pixel, compute a direction toward the pixel's position on an image plane\n",
    "  at `z=-1` (relative to the origin), then normalize it\n",
    "- Use a 100x100 pixel grid covering a 3x3 region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here.\n",
    "#\n",
    "# Write a @wp.kernel called `raycast_mesh` that takes:\n",
    "#   pixel_size: float\n",
    "#   pixel_offset: wp.vec2\n",
    "#   mesh_id: wp.uint64\n",
    "#   out_texture: wp.array(dtype=wp.vec3, ndim=2)\n",
    "#\n",
    "# For each pixel (j, i = wp.tid()):\n",
    "#   1. Compute ray_origin = wp.vec3(0.0, 0.0, 5.0)\n",
    "#   2. Compute ray_dir = wp.normalize(wp.vec3(\n",
    "#        j * pixel_size + pixel_offset[0],\n",
    "#        i * pixel_size + pixel_offset[1],\n",
    "#        -1.0,\n",
    "#      ))\n",
    "#   3. Call wp.mesh_query_ray(mesh_id, ray_origin, ray_dir, 1e6)\n",
    "#   4. If hit: color = query.normal * 0.5 + wp.vec3(0.5, 0.5, 0.5)\n",
    "#   5. If miss: color = wp.vec3(0.0, 0.0, 0.0)\n",
    "#   6. Store in out_texture[i, j]\n",
    "#\n",
    "# Set up:\n",
    "#   grid_size = (3.0, 3.0), pixel_size = 0.03 (-> 100x100)\n",
    "#   Create tetrahedron mesh, allocate texture, launch kernel.\n",
    "#   Store the result in `ray_texture`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Assertions and visualization (do not modify) ---\n",
    "rt = ray_texture.numpy()\n",
    "assert rt.shape == (100, 100, 3), f\"Expected (100, 100, 3), got {rt.shape}\"\n",
    "# Center pixel should have hit the mesh (non-black)\n",
    "center_pix = rt[50, 50]\n",
    "print(f\"Center pixel: ({center_pix[0]:.2f}, {center_pix[1]:.2f}, {center_pix[2]:.2f})\")\n",
    "assert np.any(center_pix > 0.01), \"Center pixel should have hit the mesh (non-black)\"\n",
    "# Corner pixel should be black (ray missed)\n",
    "corner_pix = rt[0, 0]\n",
    "print(f\"Corner pixel: ({corner_pix[0]:.2f}, {corner_pix[1]:.2f}, {corner_pix[2]:.2f})\")\n",
    "np.testing.assert_allclose(corner_pix, [0, 0, 0], atol=0.01, err_msg=\"Corner should be black (miss)\")\n",
    "print(\"Passed!\")\n",
    "\n",
    "# Visualize (optional — requires matplotlib)\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "    ax.imshow(np.clip(rt, 0, 1), origin=\"lower\")\n",
    "    ax.set_title(\"Raycasted tetrahedron (normal coloring)\")\n",
    "    plt.show()\n",
    "except ImportError:\n",
    "    print(\"(matplotlib not available for visualization)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise 8: Break It — Mesh Winding Order\n",
    "\n",
    "### Think first\n",
    "\n",
    "The **winding order** of triangle vertices determines which side is the \"front\" (outside)\n",
    "and which is the \"back\" (inside). This directly affects `query.sign` in SDF computations\n",
    "and `query.normal` in raycasting.\n",
    "\n",
    "If you reverse the winding order of all triangles (swap two vertices in each face),\n",
    "the normals flip, and inside/outside are swapped.\n",
    "\n",
    "**Question:** If you flip the winding order of the tetrahedron from Exercise 4,\n",
    "what would happen to the SDF value at the origin? What about the ray-traced normals?\n",
    "\n",
    "<details>\n",
    "<summary>Discussion</summary>\n",
    "\n",
    "The SDF at the origin would become **positive** (the mesh now thinks the origin is\n",
    "\"outside\"). The ray-traced normals would point **inward** instead of outward, producing\n",
    "different (darker) colors since the normal-to-color mapping would give values closer\n",
    "to 0.\n",
    "</details>\n",
    "\n",
    "### Now try it\n",
    "\n",
    "Create a tetrahedron with **reversed** winding order. Compute the SDF at the origin and\n",
    "verify that the sign has flipped compared to Exercise 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here.\n",
    "#\n",
    "# The original faces were: [0,1,2], [0,2,3], [0,3,1], [1,3,2]\n",
    "# Reverse each by swapping the last two vertices:\n",
    "#   [0,2,1], [0,3,2], [0,1,3], [1,2,3]\n",
    "#\n",
    "# Create the flipped mesh, query the SDF at the origin.\n",
    "# Store the result in `flipped_sdf_val` (a single float).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Assertions (do not modify) ---\n",
    "print(f\"Flipped SDF at origin: {flipped_sdf_val}\")\n",
    "assert flipped_sdf_val > 0.0, f\"Flipped winding should make origin 'outside' (positive SDF), got {flipped_sdf_val}\"\n",
    "print(\"Passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise 9: Break It — Ray Direction\n",
    "\n",
    "Take your working raycast kernel from Exercise 7 and experiment with these changes\n",
    "**one at a time**. Predict what will happen, then run it.\n",
    "\n",
    "1. **Don't normalize** the ray direction — remove the `wp.normalize()` call\n",
    "2. **Move the camera inside** the mesh — set `ray_origin = wp.vec3(0, 0, 0)`\n",
    "3. **Point the camera away** — negate the z component of the direction\n",
    "\n",
    "<details>\n",
    "<summary>Discussion</summary>\n",
    "\n",
    "1. **Unnormalized rays:** The rendering still \"works\" visually, but `query.t` now\n",
    "   represents distance in units of the unnormalized direction vector, not world units.\n",
    "   For normal coloring this doesn't matter, but for depth calculations it would be wrong.\n",
    "\n",
    "2. **Camera inside:** You see the *inside* of the tetrahedron faces (backfaces). The\n",
    "   normals point away from you, so the normal-to-color mapping gives dark/different colors.\n",
    "\n",
    "3. **Camera facing away:** The image is entirely black — no rays hit the mesh since\n",
    "   they're pointing in the wrong direction.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment here: copy your raycast setup from Exercise 7 and try the modifications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise 10: Putting It Together — Depth Rendering\n",
    "\n",
    "Write a raycasting kernel that renders a **depth image** instead of normals.\n",
    "The depth is `query.t` — the distance from the camera to the hit point along the ray.\n",
    "\n",
    "Map depth to brightness: closer points should be **brighter** (white), and farther points\n",
    "**darker** (black). A simple mapping:\n",
    "```python\n",
    "brightness = 1.0 - (t - min_depth) / (max_depth - min_depth)\n",
    "color = wp.vec3(brightness, brightness, brightness)\n",
    "```\n",
    "\n",
    "Use `min_depth = 3.5` and `max_depth = 6.0` for the tetrahedron with a camera at `z=5`.\n",
    "Clamp brightness to `[0, 1]`.\n",
    "\n",
    "Render a 100x100 image. Pixels that miss the mesh should be black."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here.\n",
    "#\n",
    "# Write a @wp.kernel called `raycast_depth` similar to Exercise 7, but:\n",
    "#   - Store depth-based brightness instead of normal-based color\n",
    "#   - Takes additional inputs: min_depth (float) and max_depth (float)\n",
    "#\n",
    "# Create the tetrahedron mesh, set up the grid, launch the kernel.\n",
    "# Store the result in `depth_texture`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Assertions and visualization (do not modify) ---\n",
    "dt = depth_texture.numpy()\n",
    "assert dt.shape == (100, 100, 3), f\"Expected (100, 100, 3), got {dt.shape}\"\n",
    "# Center pixel should be bright (close to camera)\n",
    "center_depth = dt[50, 50]\n",
    "print(f\"Center pixel brightness: {center_depth[0]:.2f}\")\n",
    "assert center_depth[0] > 0.3, \"Center should be somewhat bright (mesh is close)\"\n",
    "# Corner should be black\n",
    "corner_depth = dt[0, 0]\n",
    "np.testing.assert_allclose(corner_depth, [0, 0, 0], atol=0.01)\n",
    "print(\"Passed!\")\n",
    "\n",
    "# Visualize (optional)\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "    ax.imshow(np.clip(dt, 0, 1), origin=\"lower\")\n",
    "    ax.set_title(\"Depth rendering of tetrahedron\")\n",
    "    plt.show()\n",
    "except ImportError:\n",
    "    print(\"(matplotlib not available for visualization)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
